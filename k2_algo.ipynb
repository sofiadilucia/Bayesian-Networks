{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dcf57ebb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(bnlearn)\n",
    "library(Rgraphviz)\n",
    "library(parallel)\n",
    "library(tidyverse)\n",
    "suppressWarnings(library(dplyr))\n",
    "\n",
    "### dataset needs to be preprocessed because  for example had values as factors. My functions does not work w/factorslearning.test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d076f",
   "metadata": {},
   "source": [
    "Today i learnt that the k2 algorithm infers the dag, the directed acyclic graph, so the structure of the bayesian network from the dataset. Not from the fitted model. \n",
    "What i initially thought was that you happen to have a model and you want to reverse engineer that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d67ca39a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "factor_remover <- function(dataset) {\n",
    "    cols <- colnames(dataset)\n",
    "    for (i in seq_along(cols)) {\n",
    "        name <- cols[i]\n",
    "        dataset[[name]] <- as.character(dataset[[name]])\n",
    "    }\n",
    "    return(dataset)\n",
    "}\n",
    "\n",
    "node.values <- function(dataset, parents) {\n",
    "    # retrieves the unique values of the nodes\n",
    "    #return a list of vectors, \n",
    "    # each vector contains the unique values of the corresponding node\n",
    "    output <- list()\n",
    "    for (kk in seq_along(parents)) {\n",
    "        node <- parents[kk]\n",
    "        node.vals <- unique(dataset[[node]]) #it was levels()\n",
    "        output[[kk]] <- node.vals\n",
    "    }\n",
    "    return(output)\n",
    "}\n",
    "\n",
    "old.alphaijk <- function(i, pii, dataset, nodes.order) {\n",
    "    actual_node <- nodes.order[i]\n",
    "    all.nodes <- c(pii, actual_node)\n",
    "    subset <- dataset[all.nodes]\n",
    "    unique.instantiations <- expand.grid(node.values(dataset, all.nodes))\n",
    "    output <- c()\n",
    "    for (tracker in 1:dim(unique.instantiations)[1]){\n",
    "        aa <- 0\n",
    "        for (j in 1:dim(subset)[1]) {\n",
    "            ifelse(all(as.vector(unlist(subset[j,])) == as.vector(unlist(unique.instantiations[tracker,]))), aa <- aa +1, FALSE)\n",
    "        }\n",
    "        output <- c(output,aa)\n",
    "    }\n",
    "    return(output)\n",
    "}\n",
    "\n",
    "fastalphaijk <- function(i, pii, dataset, nodes.order) {\n",
    "    actual_node <- nodes.order[i]\n",
    "    all.nodes <- c(pii, actual_node)\n",
    "    subset <- dataset[all.nodes]\n",
    "    unique.instantiations <- expand.grid(node.values(dataset, all.nodes))\n",
    "    colnames(unique.instantiations) <- colnames(subset)\n",
    "    subset.counted <- subset |> group_by(across(everything())) |> summarise(n = n(), .groups=\"drop\")\n",
    "    checking <-  left_join(unique.instantiations, subset.counted, by=colnames(subset), na_matches=\"na\")  |> arrange(across(-last_col()))\n",
    "    checking[is.na(checking)]<- 0\n",
    "    #print(checking)\n",
    "    return(checking$n)\n",
    "}\n",
    "\n",
    "\n",
    "k2helper <- function(i, pii, dataset, nodes.order) {\n",
    "    # the \"f\" function in the pdf\n",
    "    phi_i <- expand.grid(node.values(dataset, pii)) \n",
    "    #cat(\"\\nphi.i\")\n",
    "    #print( phi_i)\n",
    "    q_i <- dim(phi_i)[1] # works good\n",
    "    #cat(\"\\nqi.i\", q_i)\n",
    "    nodes <- colnames(dataset)\n",
    "    #cat(\"\\nnodes\", nodes)\n",
    "    i.th.node <- nodes[i]\n",
    "    #cat(\"\\nithnode\", i.th.node)\n",
    "    v_i <- node.values(dataset, i.th.node)\n",
    "    #cat(\"\\nvi\")\n",
    "    #print( v_i)\n",
    "    r_i <- length(v_i[[1]])\n",
    "    #cat(\"ri\", r_i)\n",
    "    individual_alphas <- fastalphaijk(i, pii, dataset, nodes.order) # works good\n",
    "    #cat(\"\\nindividual alphas::\",individual_alphas)\n",
    "    aijk <- prod(factorial(individual_alphas)) ##\n",
    "    #numeratore <- factorial(r_i-1)\n",
    "    grouping_alphas <- matrix(individual_alphas, nrow=r_i) # to get the right Nijs\n",
    "    nij <- colSums(grouping_alphas)\n",
    "    #print(nij)\n",
    "    produttoria_alpha <- prod(factorial(individual_alphas))\n",
    "    numeratore <- factorial(r_i-1)\n",
    "    denominatore <- factorial(nij+r_i-1)\n",
    "    out <- prod((numeratore/denominatore))*produttoria_alpha\n",
    "    #cat(\"\\nproduttoria_alpha\",produttoria_alpha )\n",
    "    #cat(\"\\nproduttoria_alpha\",produttoria_alpha )\n",
    "    #print(frazione)\n",
    "    return(out)\n",
    "}\n",
    "\n",
    "\n",
    "k2 <- function(dataset, nodes.order, upperbound) {\n",
    "    nodes <- colnames(dataset)\n",
    "    for (i in seq_along(nodes.order)) {\n",
    "        actual_node <- nodes.order[i]\n",
    "        #cat(\"\\n\", i,\"\\n\")\n",
    "        pii <- c()\n",
    "        p.old <- k2helper(i, pii,dataset, nodes.order)\n",
    "        #cat(\"\\n \",p.old, \"\\n should be \", 1/2772)\n",
    "        proceed <- TRUE\n",
    "        cat(\"\\ni::\",i, \"\\n\")\n",
    "        while (proceed && length(pii) < upperbound) {\n",
    "            predecessors_idx <- i-1\n",
    "            predecessors <- nodes.order[0:predecessors_idx]\n",
    "            cat(\"\\npredecessors::\", predecessors, \" pii:: \", pii)\n",
    "            piiuz <- setdiff(predecessors, pii)\n",
    "            if (length(piiuz) > 1) {\n",
    "                daddy.s.probs <- c()\n",
    "                for (daddy in seq_along(piiuz)) {\n",
    "                    p.new <- k2helper(i, piiuz[daddy], dataset, nodes.order)\n",
    "                    daddy.s.probs <- c(daddy.s.probs, p.new)\n",
    "                }\n",
    "                p.new <- max(daddy.s.probs)\n",
    "                genitore <-  piiuz[daddy.s.probs == p.new]\n",
    "            } else {\n",
    "                p.new <- k2helper(i, piiuz, dataset, nodes.order)\n",
    "                genitore <- piiuz\n",
    "            }\n",
    "            cat(\"\\npiiuz:: \",piiuz,\"\\np.old:: \", p.old, \"\\np.new:: \", p.new)\n",
    "            #roof <- roof+1\n",
    "            if (p.new > p.old) {\n",
    "                p.old <- p.new\n",
    "                pii <- c(pii, genitore)\n",
    "                #ifelse(roof>length(nodes)^length(nodes), proceed <- FALSE, proceed <- TRUE)\n",
    "            } else  {\n",
    "                proceed <- FALSE\n",
    "            }\n",
    "        }\n",
    "        cat('\\nNode', nodes.order[i], '--> Parents:', pii,'\\n') \n",
    "    }\n",
    "    return(TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "13b8374d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "###Trial with Paper dataset\n",
    "#\n",
    "#df <- data.frame(x1=c(1,1,0,1,0,0,1,0,1,0), x2=c(0,1,0,1,0,1,1,0,1,0), x3=c(0,1,1,1,0,1,1,0,1,0))\n",
    "#k2(dataset=df, upperbound=2, nodes.order=colnames(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a32090",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in data(child):\n",
      "“data set ‘child’ not found”\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Trial w/ learning.test\n",
    "df <- learning.test\n",
    "#print(sapply(df, class))\n",
    "df <- factor_remover(df)\n",
    "#print(sapply(df, class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "31be52f5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnlearn-package            package:bnlearn             R Documentation\n",
      "\n",
      "_\bB_\ba_\by_\be_\bs_\bi_\ba_\bn _\bn_\be_\bt_\bw_\bo_\br_\bk _\bs_\bt_\br_\bu_\bc_\bt_\bu_\br_\be _\bl_\be_\ba_\br_\bn_\bi_\bn_\bg, _\bp_\ba_\br_\ba_\bm_\be_\bt_\be_\br _\bl_\be_\ba_\br_\bn_\bi_\bn_\bg _\ba_\bn_\bd _\bi_\bn_\bf_\be_\br_\be_\bn_\bc_\be\n",
      "\n",
      "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
      "\n",
      "     Bayesian network structure learning (via constraint-based,\n",
      "     score-based and hybrid algorithms), parameter learning (via ML and\n",
      "     Bayesian estimators) and inference (via approximate inference\n",
      "     algorithms).\n",
      "\n",
      "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
      "\n",
      "     ‘bnlearn’ implements key algorithms covering all stages of\n",
      "     Bayesian network modelling: data preprocessing, structure learning\n",
      "     combining data and expert/prior knowledge, parameter learning, and\n",
      "     inference (including causal inference via do-calculus). ‘bnlearn’\n",
      "     aims to be a one-stop shop for Bayesian networks in R, providing\n",
      "     the tools needed for learning and working with discrete Bayesian\n",
      "     networks, Gaussian Bayesian networks and conditional linear\n",
      "     Gaussian Bayesian networks on real-world data. Incomplete data\n",
      "     with missing values are also supported. Furthermore the modular\n",
      "     nature of ‘bnlearn’ makes it easy to use it for simulation\n",
      "     studies.\n",
      "\n",
      "     Implemented structure learning algorithms include:\n",
      "\n",
      "        • _Constraint-based algorithms_, which use conditional\n",
      "          independence tests to learn conditional independence\n",
      "          constraints from data. The constraints in turn are used to\n",
      "          learn the structure of the Bayesian network under the\n",
      "          assumption that conditional independence implies graphical\n",
      "          separation (so, two variables that are independent cannot be\n",
      "          connected by an arc).\n",
      "\n",
      "        • _Score-based algorithms_, which are general-purpose\n",
      "          optimization algorithms that rank network structures with\n",
      "          respect to a goodness-of-fit score.\n",
      "\n",
      "        • _Hybrid algorithms_ combine aspects of both constraint-based\n",
      "          and score-based algorithms, as they use conditional\n",
      "          independence tests (usually to reduce the search space) and\n",
      "          network scores (to find the optimal network in the reduced\n",
      "          space) at the same time.\n",
      "\n",
      "     For more details about structure learning algorithms see structure\n",
      "     learning; available conditional independence tests are described\n",
      "     in independence tests and available network scores are described\n",
      "     in network scores. Specialized algorithms to learn the structure\n",
      "     of Bayesian network classifiers are described in network\n",
      "     classifiers. All algorithms support the use of whitelists and\n",
      "     blacklists to include and exclude arcs from the networks (see\n",
      "     whitelists and blacklists); and many have parallel implementation\n",
      "     built on the ‘parallel’ package. Bayesian network scores support\n",
      "     the use of graphical priors.\n",
      "\n",
      "     Parameter learning approaches include both frequentist and\n",
      "     Bayesian estimators. Inference is implemented using approximate\n",
      "     algorithms via particle filters approaches such as likelihood\n",
      "     weighting, and covers conditional probability queries, prediction\n",
      "     and imputation.\n",
      "\n",
      "     Additional facilities include support for bootstrap and\n",
      "     cross-validation; advanced plotting capabilities implemented on\n",
      "     top of ‘Rgraphviz’ and ‘lattice’; model averaging; random graphs\n",
      "     and random samples generation; import/export functions to\n",
      "     integrate ‘bnlearn’ with software such as Hugin and GeNIe; an\n",
      "     associated Bayesian network repository of golden-standard networks\n",
      "     at <https://www.bnlearn.com/bnrepository/>.\n",
      "\n",
      "     Use ‘citation(\"bnlearn\")’ to find out how to cite ‘bnlearn’ in\n",
      "     publications and other materials; and visit\n",
      "     <https://www.bnlearn.com/> for more examples and code from\n",
      "     publications using ‘bnlearn’.\n",
      "\n",
      "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
      "\n",
      "     Marco Scutari\n",
      "     Istituto Dalle Molle di Studi sull'Intelligenza Artificiale\n",
      "     (IDSIA)\n",
      "     Maintainer: Marco Scutari <mailto:scutari@bnlearn.com>\n",
      "\n",
      "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
      "\n",
      "     *reference books:*\n",
      "\n",
      "     Koller D, Friedman N (2009). _Probabilistic Graphical Models:\n",
      "     Principles and Techniques_. MIT Press.\n",
      "\n",
      "     Korb K, Nicholson AE (2010). _Bayesian Artificial Intelligence_.\n",
      "     Chapman & Hall/CRC, 2nd edition.\n",
      "\n",
      "     Pearl J (1988). _Probabilistic Reasoning in Intelligent Systems:\n",
      "     Networks of Plausible Inference_. Morgan Kaufmann.\n",
      "\n",
      "     *from the author:*\n",
      "\n",
      "     Nagarajan R, Scutari M, Lebre S (2013). \"Bayesian Networks in R\n",
      "     with Applications in Systems Biology\". Springer.\n",
      "\n",
      "     Scutari M (2010). \"Learning Bayesian Networks with the bnlearn R\n",
      "     Package\".  _Journal of Statistical Software_, *35*(3):1-22.\n",
      "\n",
      "     Scutari M (20107). \"Bayesian Network Constraint-Based Structure\n",
      "     Learning Algorithms: Parallel and Optimized Implementations in the\n",
      "     bnlearn R Package\". _Journal of Statistical Software_,\n",
      "     *77*(2):1-20.\n",
      "\n",
      "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
      "\n",
      "     ## the workflow of Bayesian network modelling in bnlearn:\n",
      "     # choose the data set to work on...\n",
      "     data(learning.test)\n",
      "     # ... choose an algorithm and learn the structure of the network from the data...\n",
      "     net = hc(learning.test)\n",
      "     # ... plot it...\n",
      "     ## Not run: graphviz.plot(net)\n",
      "     # ... learn the parameters of the network...\n",
      "     bn = bn.fit(net, learning.test)\n",
      "     # ... explore the network with a classic barchart...\n",
      "     ## Not run: graphviz.chart(bn)\n",
      "     # ... and perform inference to answer any question that interests you!\n",
      "     cpquery(bn, event = (A == \"a\"), evidence = (C == \"a\"))\n",
      "     "
     ]
    }
   ],
   "source": [
    "?bnlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7bb6d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
